{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostRegressor,  BaggingRegressor, ExtraTreesRegressor, GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import yfinance as yf  # for data\n",
    "from pandas_datareader import data as pdr\n",
    "yf.pdr_override()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(stock='TSLA', period = \"7d\", interval = \"2m\"):\n",
    "    '''\n",
    "    reading the data\n",
    "    '''\n",
    "\n",
    "\n",
    "    df = pdr.get_data_yahoo(stock,period = period,\n",
    "\n",
    "            # fetch data by interval (including intraday if period < 60 days)\n",
    "            # valid intervals: 1m,2m,5m,15m,30m,60m,90m,1h,1d,5d,1wk,1mo,3mo\n",
    "            # (optional, default is '1d')\n",
    "            interval = interval,)\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "df1 = read_data(stock='TSLA').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>2020-11-10 15:50:00-05:00</td>\n",
       "      <td>409.920013</td>\n",
       "      <td>410.850006</td>\n",
       "      <td>409.200012</td>\n",
       "      <td>409.269989</td>\n",
       "      <td>409.269989</td>\n",
       "      <td>140984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>2020-11-10 15:52:00-05:00</td>\n",
       "      <td>409.248291</td>\n",
       "      <td>409.760010</td>\n",
       "      <td>408.730011</td>\n",
       "      <td>409.570007</td>\n",
       "      <td>409.570007</td>\n",
       "      <td>109845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>2020-11-10 15:54:00-05:00</td>\n",
       "      <td>409.626312</td>\n",
       "      <td>410.119995</td>\n",
       "      <td>409.114288</td>\n",
       "      <td>409.730011</td>\n",
       "      <td>409.730011</td>\n",
       "      <td>107881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>2020-11-10 15:56:00-05:00</td>\n",
       "      <td>409.809998</td>\n",
       "      <td>410.820007</td>\n",
       "      <td>409.510010</td>\n",
       "      <td>410.109985</td>\n",
       "      <td>410.109985</td>\n",
       "      <td>171583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>2020-11-10 15:58:00-05:00</td>\n",
       "      <td>410.070007</td>\n",
       "      <td>410.880005</td>\n",
       "      <td>409.950012</td>\n",
       "      <td>410.410004</td>\n",
       "      <td>410.410004</td>\n",
       "      <td>231045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Datetime        Open        High         Low  \\\n",
       "1360 2020-11-10 15:50:00-05:00  409.920013  410.850006  409.200012   \n",
       "1361 2020-11-10 15:52:00-05:00  409.248291  409.760010  408.730011   \n",
       "1362 2020-11-10 15:54:00-05:00  409.626312  410.119995  409.114288   \n",
       "1363 2020-11-10 15:56:00-05:00  409.809998  410.820007  409.510010   \n",
       "1364 2020-11-10 15:58:00-05:00  410.070007  410.880005  409.950012   \n",
       "\n",
       "           Close   Adj Close  Volume  \n",
       "1360  409.269989  409.269989  140984  \n",
       "1361  409.570007  409.570007  109845  \n",
       "1362  409.730011  409.730011  107881  \n",
       "1363  410.109985  410.109985  171583  \n",
       "1364  410.410004  410.410004  231045  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is the tail of the df which has the most recent data\n",
    "df1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have the follwoing model already established"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stock(dfx,intra =True):\n",
    "    \"\"\"\n",
    "    predict the price for the closing price for the bext inerval. \n",
    "    \n",
    "    inputs:\n",
    "    ------\n",
    "    - stock: string, symobol for the stick, eg. 'TSLA'\n",
    "    - intra : Boolean, if True then the period and interval should be 1m, 5m, etc, if False it should be 1d, 7d, etc\n",
    "    - period : total period\n",
    "    - interval : interval for the data\n",
    "    \n",
    "    \"\"\"\n",
    "    df = dfx.copy()\n",
    "    #print(len(df))\n",
    "    print(df.tail(1)['Datetime'])\n",
    "    old = df.tail(1).loc[:,'Open'].to_numpy()[0]\n",
    "    \n",
    "    if intra ==True:\n",
    "            df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "            df['Datetime']=df['Datetime'].map(dt.datetime.toordinal)\n",
    "            df['SMA_1'] = df['Adj Close'].rolling(window = 26).mean()\n",
    "            df['SMA_2'] = df['Adj Close'].rolling(window = 50).mean()\n",
    "            df['status_sma_lower'] = np.where(df['Adj Close'] < df['SMA_1'],'below_movavg','normal')\n",
    "            df['status_sma_upper'] = np.where(df['Adj Close'] > df['SMA_2'],'above_movavg','normal')\n",
    "    \n",
    "    elif intra ==False:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df['Date']=df['Date'].map(dt.datetime.toordinal)\n",
    "#             df['SMA_1'] = df['Adj Close'].rolling(window = 50).mean()\n",
    "#             df['SMA_2'] = df['Adj Close'].rolling(window = 100).mean()\n",
    "#             df['status_sma_lower'] = np.where(df['Adj Close'] < df['SMA_1'],'below_movavg','normal')\n",
    "#             df['status_sma_upper'] = np.where(df['Adj Close'] > df['SMA_2'],'above_movavg','normal')\n",
    "\n",
    "     \n",
    "    df['High'] = df['High'].shift(1)\n",
    "    df['Low'] = df['Low'].shift(1)\n",
    "    df['Volume'] = df['Volume'].shift(1) \n",
    "    df['Middle Band'] =df['Adj Close'].rolling(window=26).mean()\n",
    "    df['Upper Band'] = df['Middle Band'] + 1.96*df['Adj Close'].rolling(window=20).std()\n",
    "    df['Lower Band'] = df['Middle Band'] - 1.96*df['Adj Close'].rolling(window=20).std()\n",
    "    df['status_lower'] = np.where(df['Adj Close'] < df['Lower Band'],'below_ballinger','normal')\n",
    "    df['status_upper'] = np.where(df['Adj Close'] > df['Upper Band'],'above_ballinger','normal')\n",
    "    #df['f01'] = df['Close']/df['Open']-1\n",
    "\n",
    "\n",
    "    df = df.dropna()\n",
    "    df = df.drop(columns = ['Close'])\n",
    "    y = df['Adj Close']\n",
    "    X = df.drop(columns =['Adj Close','Volume' ,'Low','High'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,shuffle= False)\n",
    "        # first transformer for the numeric features\n",
    "    numeric_features = list(set(list(X_train.columns)) - set(['status_lower','status_upper','status_sma_lower','status_sma_upper']))\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "       ])\n",
    "    # now a taransformer for the categorical features\n",
    "    categorical_features = ['status_lower','status_upper']\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    # creating a preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "    \n",
    "    ridge_model = Ridge()\n",
    "    # include the preprocessor and the model in one pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    reg_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('Regressor', ridge_model)])\n",
    "\n",
    "    # finally we will pass the pipe line to gridsearchcv to find the optimum paramters for the model\n",
    "    param_grid = {\n",
    "        'Regressor__alpha':[0.1,0.25,0.4],\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    search = GridSearchCV(reg_pipeline,param_grid,cv = 5)\n",
    "\n",
    "    # fitting the model\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    # printing the first parameter\n",
    "    #rint(search.best_params_)\n",
    "    print(\"model score: %.3f\" % search.score(X_test, y_test))\n",
    "    X_train = X[:-1]\n",
    "    y_train = y[:-1]\n",
    "    X_test = X[-1:]\n",
    "    y_test = y[-1:]\n",
    "    search.fit(X_train,y_train)\n",
    "    y_pred = search.predict(X_train)\n",
    "    print('error',np.sqrt(mean_squared_error(y_train,y_pred)))\n",
    "    y_test = search.predict(X_test)[0]\n",
    "    diff = y_test - old\n",
    "   \n",
    "    print('old price = ',old)\n",
    "    print('predicted = ',y_test)\n",
    "    print('difference = ', diff)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's see the power of feature engineering:\n",
    "#we will add the daily return as a feature for this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stock_w_feature(dfx,intra =True):\n",
    "    \"\"\"\n",
    "    predict the price for the closing price for the bext inerval. \n",
    "    \n",
    "    inputs:\n",
    "    ------\n",
    "    - stock: string, symobol for the stick, eg. 'TSLA'\n",
    "    - intra : Boolean, if True then the period and interval should be 1m, 5m, etc, if False it should be 1d, 7d, etc\n",
    "    - period : total period\n",
    "    - interval : interval for the data\n",
    "    \n",
    "    \"\"\"\n",
    "    #print(len(df))\n",
    "    df = dfx.copy()\n",
    "    df['f01'] = df['Close']/df['Open']-1\n",
    "    print(df.tail(1)['Datetime'])\n",
    "    old = df.tail(1).loc[:,'Open'].to_numpy()[0]\n",
    "    \n",
    "    if intra ==True:\n",
    "            df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "            df['Datetime']=df['Datetime'].map(dt.datetime.toordinal)\n",
    "            df['SMA_1'] = df['Adj Close'].rolling(window = 26).mean()\n",
    "            df['SMA_2'] = df['Adj Close'].rolling(window = 50).mean()\n",
    "            df['status_sma_lower'] = np.where(df['Adj Close'] < df['SMA_1'],'below_movavg','normal')\n",
    "            df['status_sma_upper'] = np.where(df['Adj Close'] > df['SMA_2'],'above_movavg','normal')\n",
    "    \n",
    "    elif intra ==False:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df['Date']=df['Date'].map(dt.datetime.toordinal)\n",
    "#             df['SMA_1'] = df['Adj Close'].rolling(window = 50).mean()\n",
    "#             df['SMA_2'] = df['Adj Close'].rolling(window = 100).mean()\n",
    "#             df['status_sma_lower'] = np.where(df['Adj Close'] < df['SMA_1'],'below_movavg','normal')\n",
    "#             df['status_sma_upper'] = np.where(df['Adj Close'] > df['SMA_2'],'above_movavg','normal')\n",
    "\n",
    "     \n",
    "    df['High'] = df['High'].shift(1)\n",
    "    df['Low'] = df['Low'].shift(1)\n",
    "    df['Volume'] = df['Volume'].shift(1)\n",
    "    df['Middle Band'] =df['Adj Close'].rolling(window=26).mean()\n",
    "    df['Upper Band'] = df['Middle Band'] + 1.96*df['Adj Close'].rolling(window=20).std()\n",
    "    df['Lower Band'] = df['Middle Band'] - 1.96*df['Adj Close'].rolling(window=20).std()\n",
    "    df['status_lower'] = np.where(df['Adj Close'] < df['Lower Band'],'below_ballinger','normal')\n",
    "    df['status_upper'] = np.where(df['Adj Close'] > df['Upper Band'],'above_ballinger','normal')\n",
    "    #df['f01'] = df['Close']/df['Open']-1\n",
    "\n",
    "\n",
    "    df = df.dropna()\n",
    "    df = df.drop(columns = ['Close'])\n",
    "    y = df['Adj Close']\n",
    "    X = df.drop(columns =['Adj Close','Volume' ,'Low','High'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,shuffle= False)\n",
    "        # first transformer for the numeric features\n",
    "    numeric_features = list(set(list(X_train.columns)) - set(['status_lower','status_upper','status_sma_lower','status_sma_upper']))\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "       ])\n",
    "    # now a taransformer for the categorical features\n",
    "    categorical_features = ['status_lower','status_upper']\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    # creating a preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "    \n",
    "    ridge_model = Ridge()\n",
    "    # include the preprocessor and the model in one pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    reg_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('Regressor', ridge_model)])\n",
    "\n",
    "    # finally we will pass the pipe line to gridsearchcv to find the optimum paramters for the model\n",
    "    param_grid = {\n",
    "        'Regressor__alpha':[0.1,0.25,0.4],\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    search = GridSearchCV(reg_pipeline,param_grid,cv = 5)\n",
    "\n",
    "    # fitting the model\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    # printing the first parameter\n",
    "    #rint(search.best_params_)\n",
    "    print(\"model score: %.3f\" % search.score(X_test, y_test))\n",
    "    X_train = X[:-1]\n",
    "    y_train = y[:-1]\n",
    "    X_test = X[-1:]\n",
    "    y_test = y[-1:]\n",
    "    search.fit(X_train,y_train)\n",
    "    y_pred = search.predict(X_train)\n",
    "    print('error',np.sqrt(mean_squared_error(y_train,y_pred)))\n",
    "    y_test = search.predict(X_test)[0]\n",
    "    diff = y_test - old\n",
    "   \n",
    "    print('old price = ',old)\n",
    "    print('predicted = ',y_test)\n",
    "    print('difference = ', diff)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1364   2020-11-10 15:58:00-05:00\n",
      "Name: Datetime, dtype: datetime64[ns, America/New_York]\n",
      "model score: 0.995\n",
      "error 0.7850662094742852\n",
      "old price =  410.07000732421875\n",
      "predicted =  410.76869542268764\n",
      "difference =  0.6986880984688923\n"
     ]
    }
   ],
   "source": [
    "# let's predict he clost price for TSLA after 5 minutes\n",
    "test_stock(df1, intra = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1364   2020-11-10 15:58:00-05:00\n",
      "Name: Datetime, dtype: datetime64[ns, America/New_York]\n",
      "model score: 1.000\n",
      "error 0.02704167567744686\n",
      "old price =  410.07000732421875\n",
      "predicted =  410.4202450461427\n",
      "difference =  0.35023772192397473\n"
     ]
    }
   ],
   "source": [
    "test_stock_w_feature(df1,intra =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do we same the same gain if use a different modeel: Random Forest ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stock_grad(dfx, intra = True):\n",
    "    \"\"\"\n",
    "    predict the price for the closing price for the bext inerval. \n",
    "    \n",
    "    inputs:\n",
    "    ------\n",
    "    - stock: string, symobol for the stick, eg. 'TSLA'\n",
    "    - intra : Boolean, if True then the period and interval should be 1m, 5m, etc, if False it should be 1d, 7d, etc\n",
    "    - period : total period\n",
    "    - interval : interval for the data\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    df = dfx.copy()\n",
    "\n",
    "    \n",
    "    #print(len(df))\n",
    "    print(df.tail(1)['Datetime'])\n",
    "    old = df.tail(1).loc[:,'Open'].to_numpy()[0]\n",
    "    \n",
    "    if intra ==True:\n",
    "            df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "            df['Datetime']=df['Datetime'].map(dt.datetime.toordinal)\n",
    "            df['SMA_1'] = df['Adj Close'].rolling(window = 26).mean()\n",
    "            df['SMA_2'] = df['Adj Close'].rolling(window = 50).mean()\n",
    "            df['status_sma_lower'] = np.where(df['Adj Close'] < df['SMA_1'],'below_movavg','normal')\n",
    "            df['status_sma_upper'] = np.where(df['Adj Close'] > df['SMA_2'],'above_movavg','normal')\n",
    "    \n",
    "    elif intra ==False:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df['Date']=df['Date'].map(dt.datetime.toordinal)\n",
    "#             df['SMA_1'] = df['Adj Close'].rolling(window = 50).mean()\n",
    "#             df['SMA_2'] = df['Adj Close'].rolling(window = 100).mean()\n",
    "#             df['status_sma_lower'] = np.where(df['Adj Close'] < df['SMA_1'],'below_movavg','normal')\n",
    "#             df['status_sma_upper'] = np.where(df['Adj Close'] > df['SMA_2'],'above_movavg','normal')\n",
    "\n",
    "     \n",
    "    df['High'] = df['High'].shift(1)\n",
    "    df['Low'] = df['Low'].shift(1)\n",
    "    df['Volume'] = df['Volume'].shift(1) \n",
    "    df['Middle Band'] =df['Adj Close'].rolling(window=26).mean()\n",
    "    df['Upper Band'] = df['Middle Band'] + 1.96*df['Adj Close'].rolling(window=20).std()\n",
    "    df['Lower Band'] = df['Middle Band'] - 1.96*df['Adj Close'].rolling(window=20).std()\n",
    "    df['status_lower'] = np.where(df['Adj Close'] < df['Lower Band'],'below_ballinger','normal')\n",
    "    df['status_upper'] = np.where(df['Adj Close'] > df['Upper Band'],'above_ballinger','normal')\n",
    "    df = df.dropna()\n",
    "    df = df.drop(columns = ['Close'])\n",
    "    y = df['Adj Close']\n",
    "    X = df.drop(columns =['Adj Close','Volume' ,'Low','High'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,shuffle= False)\n",
    "        # first transformer for the numeric features\n",
    "    numeric_features = list(set(list(X_train.columns)) - set(['status_lower','status_upper','status_sma_lower','status_sma_upper']))\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "       ])\n",
    "    # now a taransformer for the categorical features\n",
    "    categorical_features = ['status_lower']\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    # creating a preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "    ridge_model = RandomForestRegressor()\n",
    "    # include the preprocessor and the model in one pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    reg_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('Regressor', ridge_model)])\n",
    "\n",
    "    # finally we will pass the pipe line to gridsearchcv to find the optimum paramters for the model\n",
    "    param_grid = {\n",
    "        'Regressor__n_estimators':[100],\n",
    "    }\n",
    "    search = GridSearchCV(reg_pipeline,param_grid,cv = 5)\n",
    "\n",
    "    # fitting the model\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    # printing the first parameter\n",
    "    #rint(search.best_params_)\n",
    "    print(\"model score: %.3f\" % search.score(X_test, y_test))\n",
    "    X_train = X[:-1]\n",
    "    y_train = y[:-1]\n",
    "    X_test = X[-1:]\n",
    "    y_test = y[-1:]\n",
    "    search.fit(X_train,y_train)\n",
    "    y_pred = search.predict(X_train)\n",
    "    print('error',np.sqrt(mean_squared_error(y_train,y_pred)))\n",
    "    y_test = search.predict(X_test)[0]\n",
    "    diff = y_test - old\n",
    "   \n",
    "    print('old price = ',old)\n",
    "    print('predicted = ',y_test)\n",
    "    print('difference = ', diff)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stock_grad_feature(dfx, intra = True):\n",
    "    \"\"\"\n",
    "    predict the price for the closing price for the bext inerval. \n",
    "    \n",
    "    inputs:\n",
    "    ------\n",
    "    - stock: string, symobol for the stick, eg. 'TSLA'\n",
    "    - intra : Boolean, if True then the period and interval should be 1m, 5m, etc, if False it should be 1d, 7d, etc\n",
    "    - period : total period\n",
    "    - interval : interval for the data\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    df = dfx.copy()\n",
    "    \n",
    "    df['f01'] = df['Close']/df['Open']-1\n",
    "    #print(len(df))\n",
    "    print(df.tail(1)['Datetime'])\n",
    "    old = df.tail(1).loc[:,'Open'].to_numpy()[0]\n",
    "    \n",
    "    if intra ==True:\n",
    "            df['Datetime'] = pd.to_datetime(df['Datetime'])\n",
    "            df['Datetime']=df['Datetime'].map(dt.datetime.toordinal)\n",
    "            df['SMA_1'] = df['Adj Close'].rolling(window = 26).mean()\n",
    "            df['SMA_2'] = df['Adj Close'].rolling(window = 50).mean()\n",
    "            df['status_sma_lower'] = np.where(df['Adj Close'] < df['SMA_1'],'below_movavg','normal')\n",
    "            df['status_sma_upper'] = np.where(df['Adj Close'] > df['SMA_2'],'above_movavg','normal')\n",
    "    \n",
    "    elif intra ==False:\n",
    "            df['Date'] = pd.to_datetime(df['Date'])\n",
    "            df['Date']=df['Date'].map(dt.datetime.toordinal)\n",
    "#             df['SMA_1'] = df['Adj Close'].rolling(window = 50).mean()\n",
    "#             df['SMA_2'] = df['Adj Close'].rolling(window = 100).mean()\n",
    "#             df['status_sma_lower'] = np.where(df['Adj Close'] < df['SMA_1'],'below_movavg','normal')\n",
    "#             df['status_sma_upper'] = np.where(df['Adj Close'] > df['SMA_2'],'above_movavg','normal')\n",
    "\n",
    "     \n",
    "    df['High'] = df['High'].shift(1)\n",
    "    df['Low'] = df['Low'].shift(1)\n",
    "    df['Volume'] = df['Volume'].shift(1) \n",
    "    df['Middle Band'] =df['Adj Close'].rolling(window=26).mean()\n",
    "    df['Upper Band'] = df['Middle Band'] + 1.96*df['Adj Close'].rolling(window=20).std()\n",
    "    df['Lower Band'] = df['Middle Band'] - 1.96*df['Adj Close'].rolling(window=20).std()\n",
    "    df['status_lower'] = np.where(df['Adj Close'] < df['Lower Band'],'below_ballinger','normal')\n",
    "    df['status_upper'] = np.where(df['Adj Close'] > df['Upper Band'],'above_ballinger','normal')\n",
    "    df = df.dropna()\n",
    "    df = df.drop(columns = ['Close'])\n",
    "    y = df['Adj Close']\n",
    "    X = df.drop(columns =['Adj Close','Volume' ,'Low','High'])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,shuffle= False)\n",
    "        # first transformer for the numeric features\n",
    "    numeric_features = list(set(list(X_train.columns)) - set(['status_lower','status_upper','status_sma_lower','status_sma_upper']))\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "       ])\n",
    "    # now a taransformer for the categorical features\n",
    "    categorical_features = ['status_lower']\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    # creating a preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "    ridge_model = RandomForestRegressor()\n",
    "    # include the preprocessor and the model in one pipeline.\n",
    "    # Now we have a full prediction pipeline.\n",
    "    reg_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('Regressor', ridge_model)])\n",
    "\n",
    "    # finally we will pass the pipe line to gridsearchcv to find the optimum paramters for the model\n",
    "    param_grid = {\n",
    "        'Regressor__n_estimators':[100],\n",
    "    }\n",
    "    search = GridSearchCV(reg_pipeline,param_grid,cv = 5)\n",
    "\n",
    "    # fitting the model\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    # printing the first parameter\n",
    "    #rint(search.best_params_)\n",
    "    print(\"model score: %.3f\" % search.score(X_test, y_test))\n",
    "    X_train = X[:-1]\n",
    "    y_train = y[:-1]\n",
    "    X_test = X[-1:]\n",
    "    y_test = y[-1:]\n",
    "    search.fit(X_train,y_train)\n",
    "    y_pred = search.predict(X_train)\n",
    "    print('error',np.sqrt(mean_squared_error(y_train,y_pred)))\n",
    "    y_test = search.predict(X_test)[0]\n",
    "    diff = y_test - old\n",
    "   \n",
    "    print('old price = ',old)\n",
    "    print('predicted = ',y_test)\n",
    "    print('difference = ', diff)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intra-day example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ridge model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1364   2020-11-10 15:58:00-05:00\n",
      "Name: Datetime, dtype: datetime64[ns, America/New_York]\n",
      "model score: 0.841\n",
      "error 0.3374290437305777\n",
      "old price =  410.07000732421875\n",
      "predicted =  409.71956512451175\n",
      "difference =  -0.35044219970700397\n"
     ]
    }
   ],
   "source": [
    "# let's predict he clost price for TSLA after 5 minutes\n",
    "test_stock_grad(df1,intra = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1364   2020-11-10 15:58:00-05:00\n",
      "Name: Datetime, dtype: datetime64[ns, America/New_York]\n",
      "model score: 0.849\n",
      "error 0.1722698507049234\n",
      "old price =  410.07000732421875\n",
      "predicted =  410.1792889404297\n",
      "difference =  0.10928161621092158\n"
     ]
    }
   ],
   "source": [
    "test_stock_grad_feature(df1, intra = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Again we noticed an improved performance when we include this feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long term"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
